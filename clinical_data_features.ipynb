{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mne\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "import nolds as nlds\n",
    "import antropy as ant\n",
    "import mne_features as mnef\n",
    "\n",
    "from helper_code import find_data_folders, load_recording_data, get_utility_frequency, load_challenge_data, find_recording_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = 'C:\\\\Users\\\\kevin\\\\Desktop\\\\data\\\\training\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_ids = find_data_folders(data_folder)\n",
    "num_patients = len(patient_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0284', '0286', '0296', '0299', '0303', '0306', '0311']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patient_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from team_code import get_patient_features, get_eeg_features, get_ecg_features, \\\n",
    "                    reduce_channels, preprocess_data, expand_channels, \\\n",
    "                    get_outcome, get_cpc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_features(data_folder, patient_id):\n",
    "#     # Load patient data.\n",
    "#     patient_metadata = load_challenge_data(data_folder, patient_id)\n",
    "#     recording_ids = find_recording_files(data_folder, patient_id)\n",
    "#     num_recordings = len(recording_ids)\n",
    "\n",
    "#     # Extract patient features.\n",
    "#     patient_features = get_patient_features(patient_metadata)\n",
    "    \n",
    "#     print(patient_features)\n",
    "    \n",
    "#     # Extract EEG features.\n",
    "#     eeg_channels = ['F3', 'P3', 'F4', 'P4']\n",
    "#     group = 'EEG'\n",
    "\n",
    "#     if num_recordings > 0:\n",
    "#         recording_id = recording_ids[-1]\n",
    "#         recording_location = os.path.join(data_folder, patient_id, '{}_{}'.format(recording_id, group))\n",
    "#         if os.path.exists(recording_location + '.hea'):\n",
    "#             data, channels, sampling_frequency = load_recording_data(recording_location)\n",
    "#             utility_frequency = get_utility_frequency(recording_location + '.hea')\n",
    "\n",
    "#             print(channels)\n",
    "\n",
    "#             if all(channel in channels for channel in eeg_channels):\n",
    "#                 data, channels = reduce_channels(data, channels, eeg_channels)\n",
    "#                 data, sampling_frequency = preprocess_data(data, sampling_frequency, utility_frequency)\n",
    "#                 data = np.array([data[0, :] - data[1, :], data[2, :] - data[3, :]]) # Convert to bipolar montage: F3-P3 and F4-P4\n",
    "#                 eeg_features = get_eeg_features(data, sampling_frequency).flatten()\n",
    "#             else:\n",
    "#                 eeg_features = float('nan') * np.ones(8) # 2 bipolar channels * 4 features / channel\n",
    "#         else:\n",
    "#             eeg_features = float('nan') * np.ones(8) # 2 bipolar channels * 4 features / channel\n",
    "#     else:\n",
    "#         eeg_features = float('nan') * np.ones(8) # 2 bipolar channels * 4 features / channel\n",
    "\n",
    "#     # Extract ECG features.\n",
    "#     ecg_channels = ['ECG']\n",
    "#     group = 'ECG'\n",
    "\n",
    "#     if num_recordings > 0:\n",
    "#         recording_id = recording_ids[0]\n",
    "#         recording_location = os.path.join(data_folder, patient_id, '{}_{}'.format(recording_id, group))\n",
    "#         if os.path.exists(recording_location + '.hea'):\n",
    "#             data, channels, sampling_frequency = load_recording_data(recording_location)\n",
    "#             utility_frequency = get_utility_frequency(recording_location + '.hea')\n",
    "\n",
    "#             data, channels = reduce_channels(data, channels, ecg_channels)\n",
    "#             data, sampling_frequency = preprocess_data(data, sampling_frequency, utility_frequency)\n",
    "#             features = get_ecg_features(data)\n",
    "#             ecg_features = expand_channels(features, channels, ecg_channels).flatten()\n",
    "#         else:\n",
    "#             ecg_features = float('nan') * np.ones(10) # 5 channels * 2 features / channel\n",
    "#     else:\n",
    "#         ecg_features = float('nan') * np.ones(10) # 5 channels * 2 features / channel\n",
    "\n",
    "#     # Extract features.\n",
    "#     return np.hstack((patient_features, eeg_features, ecg_features))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# channels = ['Fp1', 'Fp2', 'F3', 'F4', \\\n",
    "#             'C3', 'C4', 'P3', 'P4', \\\n",
    "#             'O1', 'O2', 'F7', 'F8', \\\n",
    "#             'T3', 'T4', 'T5', 'T6', \\\n",
    "#             'Fz', 'Cz', 'Pz']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0284\n",
      "[53.  0.  1.  0. nan  1.  1. 33.]\n",
      "['Fp1', 'Fp2', 'F3', 'F4', 'C3', 'C4', 'P3', 'P4', 'O1', 'O2', 'F7', 'F8', 'T3', 'T4', 'T5', 'T6', 'Fz', 'Cz', 'Pz']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([5.30000000e+01, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,\n",
       "                  nan, 1.00000000e+00, 1.00000000e+00, 3.30000000e+01,\n",
       "       2.35810933e-04, 3.02160283e-05, 8.92759530e-06, 1.31454841e-06,\n",
       "       4.27409210e-04, 3.07961608e-05, 9.91659272e-06, 1.46806359e-06,\n",
       "       4.38920352e-01, 1.08814583e-01])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select_patient = patient_ids[0]\n",
    "# print(select_patient)\n",
    "# get_features(data_folder, select_patient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features = list()\n",
    "# outcomes = list()\n",
    "# cpcs = list()\n",
    "\n",
    "# for i in range(num_patients):\n",
    "#         if verbose >= 2:\n",
    "#             print('    {}/{}...'.format(i+1, num_patients))\n",
    "\n",
    "#         current_features = get_features(data_folder, patient_ids[i])\n",
    "#         features.append(current_features)\n",
    "\n",
    "#         # Extract labels.\n",
    "#         patient_metadata = load_challenge_data(data_folder, patient_ids[i])\n",
    "#         current_outcome = get_outcome(patient_metadata)\n",
    "#         outcomes.append(current_outcome)\n",
    "#         current_cpc = get_cpc(patient_metadata)\n",
    "#         cpcs.append(current_cpc)\n",
    "\n",
    "#     features = np.vstack(features)\n",
    "#     outcomes = np.vstack(outcomes)\n",
    "#     cpcs = np.vstack(cpcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_folder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7888/2805773431.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpatient_metadata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_challenge_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_folder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpatient_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mrecording_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_recording_files\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_folder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpatient_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mnum_recordings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecording_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data_folder' is not defined"
     ]
    }
   ],
   "source": [
    "# patient_metadata = load_challenge_data(data_folder, patient_id)\n",
    "# recording_ids = find_recording_files(data_folder, patient_id)\n",
    "# num_recordings = len(recording_ids)\n",
    "# print(\"Patient {} has {} recordings\".format(patient_id, num_recordings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "header_file = 'C:\\\\Users\\\\kevin\\\\Desktop\\\\data\\\\training\\\\0284\\\\RECORDS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n"
     ]
    }
   ],
   "source": [
    "from scipy.signal import medfilt\n",
    "\n",
    "import mne\n",
    "from mne.datasets import sample\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import (train_test_split, StratifiedKFold)\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from mne_features.feature_extraction import FeatureExtractor\n",
    "\n",
    "print(__doc__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features Extractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 300)\n",
      "perm 1.8724542145549576\n",
      "spectral [0.91386505 0.91478329 0.92487751 0.92087813 0.91513178 0.92233951\n",
      " 0.90725248 0.90065094 0.91742547 0.92067306]\n",
      "svd 6.285120413611154\n",
      "app [1.0794947461168007, 1.0735837480870112, 1.1187977097196544, 1.0802660649744098, 1.1581267922364002, 1.060060303467524, 1.0421899084853496, 1.1037643334491207, 1.0792646733382432, 1.1102235925084871]\n",
      "sample [2.1673716141865382, 2.112344942786781, 2.2573133221771813, 2.268683541318364, 2.417313358655472, 2.296799155927002, 2.156326684368051, 2.2625068694266353, 2.23018506318548, 2.2857779746776643]\n",
      "hjorth_mob [1.44385362 1.39528071 1.44033152 1.43587639 1.43821758 1.43907956\n",
      " 1.47232586 1.44891504 1.37272975 1.44710843]\n",
      "hjort_comp [1.2110549  1.25889923 1.2154379  1.20943859 1.19255638 1.20978183\n",
      " 1.18164137 1.21544326 1.26038173 1.18557986]\n",
      "num [166 139 136 155 140 155 167 153 154 162]\n"
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "# import antropy as ant\n",
    "# np.random.seed(1234567)\n",
    "# x = np.random.normal(size=[10,300])\n",
    "# print(x.shape)\n",
    "\n",
    "# # Permutation entropy\n",
    "# print('perm',ant.perm_entropy(x, normalize=True))\n",
    "# # Spectral entropy\n",
    "# print('spectral',ant.spectral_entropy(x, sf=100, method='welch', normalize=True))\n",
    "# # Singular value decomposition entropy\n",
    "# print('svd',ant.svd_entropy(x, normalize=True))\n",
    "# # Approximate entropy\n",
    "# print('app',[ant.app_entropy(i) for i in x])\n",
    "# # Sample entropy\n",
    "# print('sample',[ant.sample_entropy(i) for i in x])\n",
    "# # Hjorth mobility and complexity\n",
    "# hjorth_mob, hjorth_comp = ant.hjorth_params(x)\n",
    "# print('hjorth_mob',hjorth_mob)\n",
    "# print('hjort_comp',hjorth_comp)\n",
    "# # Number of zero-crossings\n",
    "# print('num',ant.num_zerocross(x))\n",
    "# Lempel-Ziv complexity\n",
    "# print('lziv',[ant.lziv_complexity(i, normalize=True) for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nolds as nlds\n",
    "import antropy as ant\n",
    "import mne_features as mnef\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Fractal Dimension\n",
    "- Petrosian fractal dimension\n",
    "- Katz fractal dimension\n",
    "- **Higuchi fractal dimension** Higuchi, Tomoyuki. “Approach to an irregular time series on the basis of the fractal theory.” Physica D: Nonlinear Phenomena 31.2 (1988): 277-283.\n",
    "https://www.sciencedirect.com/science/article/pii/S1568163722000939\n",
    "- Detrended fluctuation analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ptp_amp',\n",
       " 'rms',\n",
       " 'variance',\n",
       " 'skewness',\n",
       " 'kurtosis',\n",
       " 'energy_freq_bands',\n",
       " 'pow_freq_bands',\n",
       " 'hjorth_complexity_spect',\n",
       " 'hjorth_mobility_spect',\n",
       " 'higuchi_fd',\n",
       " 'katz_fd',\n",
       " 'samp_entropy',\n",
       " 'app_entropy',\n",
       " 'svd_entropy',\n",
       " 'spect_entropy',\n",
       " 'hurst_exp',\n",
       " 'svd_fisher_info',\n",
       " 'teager_kaiser_energy']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As a whole\n",
    "whole_feature_functions = [\n",
    "    # # Entropy\n",
    "    # (\"whole_perm_entropy\", lambda arr: ant.perm_entropy(arr, normalize=True)),\n",
    "    # (\"whole_svd_entropy\", lambda arr: ant.svd_entropy(arr, normalize=True)),\n",
    "    # # Fractal Dimension\n",
    "    # (\"whole_petrosian_fd\", lambda arr: ant.petrosian_fd(arr)),\n",
    "    # (\"whole_katz_fd\", lambda arr: ant.katz_fd(arr)),\n",
    "]\n",
    "\n",
    "# Per channel\n",
    "ch_feature_functions = [\n",
    "    # # Entropy\n",
    "    # (\"spectral_entropy\", lambda arr: ant.spectral_entropy(arr, sf=100, method='welch', normalize=True)),\n",
    "    # (\"hjorth_mobility\", lambda arr: ant.hjorth_params(arr)[0]),\n",
    "    # (\"hjorth_complexity\", lambda arr: ant.hjorth_params(arr)[1]),\n",
    "    # (\"app_entropy\", lambda arr: [ant.app_entropy(i) for i in arr]),\n",
    "    # (\"sample_entropy\", lambda arr: [ant.sample_entropy(i) for i in arr]),\n",
    "    # # Fractal Dimension\n",
    "    # (\"detrended_fluctuation\", lambda arr: [ant.detrended_fluctuation(i) for i in arr])\n",
    "]\n",
    "\n",
    "# Per channel\n",
    "mne_feature_functions = [\n",
    "    # Time domain\n",
    "    \"ptp_amp\",\n",
    "    \"rms\",\n",
    "    \"variance\",\n",
    "    \"skewness\",\n",
    "    \"kurtosis\",\n",
    "    # Bandpower\n",
    "    \"energy_freq_bands\",\n",
    "    \"pow_freq_bands\",\n",
    "    # Hjorth parameters\n",
    "    \"hjorth_complexity_spect\",\n",
    "    \"hjorth_mobility_spect\",\n",
    "    # Fractal Dimension\n",
    "    \"higuchi_fd\",\n",
    "    \"katz_fd\",\n",
    "    # Entropy\n",
    "    \"samp_entropy\",\n",
    "    \"app_entropy\",\n",
    "    \"svd_entropy\",\n",
    "    \"spect_entropy\",\n",
    "    # Domain-specific\n",
    "    \"hurst_exp\",\n",
    "    \"svd_fisher_info\",\n",
    "    \"teager_kaiser_energy\",\n",
    "]\n",
    "\n",
    "# mnef.get_univariate_funcs(100), mnef.get_bivariate_funcs(100)\n",
    "\n",
    "feature_functions = mne_feature_functions + ch_feature_functions + whole_feature_functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39.0"
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(741/19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 494,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "12*2+len(feature_functions)-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delta_psd, delta_freq = mne.time_frequency.psd_array_welch(arr, sfreq=100,  fmin=0.5,  fmax=4.0)\n",
    "# theta_psd, theta_freq = mne.time_frequency.psd_array_welch(arr, sfreq=100,  fmin=4.0,  fmax=8.0)\n",
    "# alpha_psd, alpha_freq = mne.time_frequency.psd_array_welch(arr, sfreq=100,  fmin=8.0, fmax=12.0)\n",
    "# beta_psd,  beta_freq = mne.time_frequency.psd_array_welch(arr, sfreq=100, fmin=12.0, fmax=30.0)\n",
    "# gamma_psd, gamma_freq = mne.time_frequency.psd_array_welch(arr, sfreq=100, fmin=30.0, fmax=100.0)   \n",
    "# # combine all list  \n",
    "\n",
    "# # put all in list and plot it with the freq and its psd\n",
    "# lst_psd = [delta_psd, theta_psd, alpha_psd, beta_psd, gamma_psd]\n",
    "# lst_freq = [delta_freq, theta_freq, alpha_freq, beta_freq, gamma_freq]\n",
    "# label = ['delta', 'theta', 'alpha', 'beta', 'gamma']\n",
    "# # Plot data in a 2D plot figure per channel\n",
    "# fig, axes = plt.subplots(nrows=19, ncols=1, figsize=(10, 50))\n",
    "# for i in range(len(lst_psd)):\n",
    "#     for ch in range(19):\n",
    "#         axes[ch].plot(lst_freq[i], lst_psd[i][ch])\n",
    "#         # Set  line colour and its label\n",
    "#         axes[ch].set_title(channels[ch])\n",
    "#         axes[ch].set_xlabel('Frequency (Hz)')\n",
    "#         axes[ch].set_ylabel('Power (dB)')\n",
    "#         axes[ch].set_xlim([0, 100])\n",
    "#         axes[ch].set_ylim([0, 0.01])\n",
    "#         axes[ch].grid(True)\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # print find all psd and freq shape\n",
    "# print(delta_psd.shape)\n",
    "# print(theta_psd.shape)\n",
    "# print(alpha_psd.shape)\n",
    "# print(beta_psd.shape)\n",
    "# print(delta_freq.shape)\n",
    "# print(theta_freq.shape)\n",
    "# print(alpha_freq.shape)\n",
    "# print(beta_freq.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def toDataFrame(result, channels, *feature_functions):\n",
    "#     \"\"\" toDataFrame(result, channels, *feature_functions)\n",
    "#         Args:\n",
    "#             result: result of feature function (n_data) (dont forget: np.flatten().reshape(1,-1))\n",
    "#             channels: list of channels\n",
    "#             feature_functions: list of feature functions\n",
    "#         Returns:\n",
    "#             df: pandas DataFrame\n",
    "#     \"\"\"\n",
    "#     df = pd.DataFrame(result, \\\n",
    "#                       columns=[f'{channel}_{name}' \\\n",
    "#                                 for ff in feature_functions \\\n",
    "#                                 for name, func in ff\\\n",
    "#                                 for channel in channels])\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fp1_spectral_entropy</th>\n",
       "      <th>Fp2_spectral_entropy</th>\n",
       "      <th>F3_spectral_entropy</th>\n",
       "      <th>F4_spectral_entropy</th>\n",
       "      <th>C3_spectral_entropy</th>\n",
       "      <th>C4_spectral_entropy</th>\n",
       "      <th>P3_spectral_entropy</th>\n",
       "      <th>P4_spectral_entropy</th>\n",
       "      <th>O1_spectral_entropy</th>\n",
       "      <th>O2_spectral_entropy</th>\n",
       "      <th>...</th>\n",
       "      <th>O2_detrended_fluctuation</th>\n",
       "      <th>F7_detrended_fluctuation</th>\n",
       "      <th>F8_detrended_fluctuation</th>\n",
       "      <th>T3_detrended_fluctuation</th>\n",
       "      <th>T4_detrended_fluctuation</th>\n",
       "      <th>T5_detrended_fluctuation</th>\n",
       "      <th>T6_detrended_fluctuation</th>\n",
       "      <th>Fz_detrended_fluctuation</th>\n",
       "      <th>Cz_detrended_fluctuation</th>\n",
       "      <th>Pz_detrended_fluctuation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.982993</td>\n",
       "      <td>0.982638</td>\n",
       "      <td>0.985728</td>\n",
       "      <td>0.983057</td>\n",
       "      <td>0.978242</td>\n",
       "      <td>0.986079</td>\n",
       "      <td>0.982229</td>\n",
       "      <td>0.981677</td>\n",
       "      <td>0.984598</td>\n",
       "      <td>0.9778</td>\n",
       "      <td>...</td>\n",
       "      <td>0.562688</td>\n",
       "      <td>0.545971</td>\n",
       "      <td>0.527285</td>\n",
       "      <td>0.471917</td>\n",
       "      <td>0.5415</td>\n",
       "      <td>0.50557</td>\n",
       "      <td>0.498962</td>\n",
       "      <td>0.572531</td>\n",
       "      <td>0.511424</td>\n",
       "      <td>0.559867</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 171 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Fp1_spectral_entropy  Fp2_spectral_entropy  F3_spectral_entropy  \\\n",
       "0              0.982993              0.982638             0.985728   \n",
       "\n",
       "   F4_spectral_entropy  C3_spectral_entropy  C4_spectral_entropy  \\\n",
       "0             0.983057             0.978242             0.986079   \n",
       "\n",
       "   P3_spectral_entropy  P4_spectral_entropy  O1_spectral_entropy  \\\n",
       "0             0.982229             0.981677             0.984598   \n",
       "\n",
       "   O2_spectral_entropy  ...  O2_detrended_fluctuation  \\\n",
       "0               0.9778  ...                  0.562688   \n",
       "\n",
       "   F7_detrended_fluctuation  F8_detrended_fluctuation  \\\n",
       "0                  0.545971                  0.527285   \n",
       "\n",
       "   T3_detrended_fluctuation  T4_detrended_fluctuation  \\\n",
       "0                  0.471917                    0.5415   \n",
       "\n",
       "   T5_detrended_fluctuation  T6_detrended_fluctuation  \\\n",
       "0                   0.50557                  0.498962   \n",
       "\n",
       "   Fz_detrended_fluctuation  Cz_detrended_fluctuation  \\\n",
       "0                  0.572531                  0.511424   \n",
       "\n",
       "   Pz_detrended_fluctuation  \n",
       "0                  0.559867  \n",
       "\n",
       "[1 rows x 171 columns]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# toDataFrame(.flatten().reshape(1,-1), channels, list_ent_feature_functions, fd_feature_functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'channels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5360/3261199413.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mchannels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'channels' is not defined"
     ]
    }
   ],
   "source": [
    "channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfreq = 100\n",
    "\n",
    "eeg_channels = ['Fp1', 'Fp2', 'F3', 'F4', \\\n",
    "            'C3', 'C4', 'P3', 'P4', \\\n",
    "            'O1', 'O2', 'F7', 'F8', \\\n",
    "            'T3', 'T4', 'T5', 'T6', \\\n",
    "            'Fz', 'Cz', 'Pz']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.normal(size=[10,19,6000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_bands = np.array([0.5, 4.0, 8.0, 13.0, 30.0, 49.9])\n",
    "params = {'pow_freq_bands__freq_bands': freq_bands, \"energy_freq_bands__freq_bands\": freq_bands}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_funcs = feature_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mne_features.feature_extraction import FeatureExtractor, extract_features\n",
    "\n",
    "\n",
    "def extract_data_per_chunk(data, chunk_size, extract_features):\n",
    "    n_chunks = len(data) // chunk_size + (len(data) % chunk_size != 0)\n",
    "\n",
    "    for i in range ()\n",
    "    x_features = extract_features(x, sfreq, selected_funcs, funcs_params=params, n_jobs=1,\n",
    "                        ch_names=eeg_channels, return_as_df=True)\n",
    "    if i == 0:\n",
    "        df.to_csv('all_features.csv', mode='w', header=True)\n",
    "    else:\n",
    "        df.to_csv('all_features.csv', mode='a', header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 741)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.random.normal(size=[10,])\n",
    "y[y>0] = 1\n",
    "y[y<=0] = 0 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "\n",
    "gb = Pipeline([('GDBoost', GradientBoostingRegressor())])\n",
    "histgb = Pipeline([('HistGDBoost', HistGradientBoostingRegressor())])\n",
    "lgbm = Pipeline([('LGBM', LGBMRegressor())])\n",
    "ada = Pipeline([('Ada', AdaBoostRegressor())])\n",
    "bag = Pipeline([('bagging', BaggingRegressor(KNeighborsRegressor(), max_samples=0.5, max_features=0.5))])\n",
    "et = Pipeline([('ExtremeForest', ExtraTreesRegressor())])\n",
    "rf = Pipeline([('RandomForest', RandomForestRegressor())])\n",
    "catb = Pipeline([('CatBoost', CatBoostRegressor(verbose=False))])\n",
    "\n",
    "# dict the name and its each model\n",
    "model_dict = {\n",
    "    # 'gb' : gb, \n",
    "    'histgb' : histgb, \n",
    "    # 'lgbm' : lgbm, \n",
    "    'ada' : ada, \n",
    "    'bag' : bag, \n",
    "    'et' : et, \n",
    "    'rf' : rf, \n",
    "    # 'catb' : catb, \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('HistGDBoost', HistGradientBoostingRegressor())])\n",
      "Pipeline(steps=[('Ada', AdaBoostRegressor())])\n",
      "Pipeline(steps=[('bagging',\n",
      "                 BaggingRegressor(base_estimator=KNeighborsRegressor(),\n",
      "                                  max_features=0.5, max_samples=0.5))])\n",
      "Pipeline(steps=[('ExtremeForest', ExtraTreesRegressor())])\n",
      "Pipeline(steps=[('RandomForest', RandomForestRegressor())])\n"
     ]
    }
   ],
   "source": [
    "for name, clf in model_dict.items():\n",
    "    print(clf)\n",
    "    # scores = cross_val_score(clf, x_features, y, cv=3, scoring='roc_auc')\n",
    "    # print(scores)\n",
    "    # print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Python38\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 106, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"c:\\Python38\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 384, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
      "  File \"c:\\Python38\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 571, in roc_auc_score\n",
      "    return _average_binary_score(\n",
      "  File \"c:\\Python38\\lib\\site-packages\\sklearn\\metrics\\_base.py\", line 75, in _average_binary_score\n",
      "    return binary_metric(y_true, y_score, sample_weight=sample_weight)\n",
      "  File \"c:\\Python38\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 339, in _binary_roc_auc_score\n",
      "    raise ValueError(\n",
      "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Python38\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 106, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"c:\\Python38\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 384, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
      "  File \"c:\\Python38\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 571, in roc_auc_score\n",
      "    return _average_binary_score(\n",
      "  File \"c:\\Python38\\lib\\site-packages\\sklearn\\metrics\\_base.py\", line 75, in _average_binary_score\n",
      "    return binary_metric(y_true, y_score, sample_weight=sample_weight)\n",
      "  File \"c:\\Python38\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 339, in _binary_roc_auc_score\n",
      "    raise ValueError(\n",
      "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Python38\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 106, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"c:\\Python38\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 384, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
      "  File \"c:\\Python38\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 571, in roc_auc_score\n",
      "    return _average_binary_score(\n",
      "  File \"c:\\Python38\\lib\\site-packages\\sklearn\\metrics\\_base.py\", line 75, in _average_binary_score\n",
      "    return binary_metric(y_true, y_score, sample_weight=sample_weight)\n",
      "  File \"c:\\Python38\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 339, in _binary_roc_auc_score\n",
      "    raise ValueError(\n",
      "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Python38\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 106, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"c:\\Python38\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 384, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
      "  File \"c:\\Python38\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 571, in roc_auc_score\n",
      "    return _average_binary_score(\n",
      "  File \"c:\\Python38\\lib\\site-packages\\sklearn\\metrics\\_base.py\", line 75, in _average_binary_score\n",
      "    return binary_metric(y_true, y_score, sample_weight=sample_weight)\n",
      "  File \"c:\\Python38\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 339, in _binary_roc_auc_score\n",
      "    raise ValueError(\n",
      "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Python38\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 106, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"c:\\Python38\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 355, in _score\n",
      "    y_pred = method_caller(clf, \"predict\", X)\n",
      "  File \"c:\\Python38\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 71, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"c:\\Python38\\lib\\site-packages\\sklearn\\pipeline.py\", line 458, in predict\n",
      "    return self.steps[-1][1].predict(Xt, **predict_params)\n",
      "  File \"c:\\Python38\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py\", line 1170, in predict\n",
      "    all_y_hat = Parallel(n_jobs=n_jobs, verbose=self.verbose)(\n",
      "  File \"c:\\Python38\\lib\\site-packages\\joblib\\parallel.py\", line 1085, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Python38\\lib\\site-packages\\joblib\\parallel.py\", line 901, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Python38\\lib\\site-packages\\joblib\\parallel.py\", line 819, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Python38\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Python38\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 597, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Python38\\lib\\site-packages\\joblib\\parallel.py\", line 288, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Python38\\lib\\site-packages\\joblib\\parallel.py\", line 288, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Python38\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 117, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Python38\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py\", line 211, in _parallel_predict_regression\n",
      "    return sum(\n",
      "  File \"c:\\Python38\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py\", line 212, in <genexpr>\n",
      "    estimator.predict(X[:, features])\n",
      "  File \"c:\\Python38\\lib\\site-packages\\sklearn\\neighbors\\_regression.py\", line 229, in predict\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "  File \"c:\\Python38\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 749, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples,  but n_samples = 1, n_neighbors = 5\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "1 fits failed out of a total of 2.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Python38\\lib\\site-packages\\sklearn\\pipeline.py\", line 382, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"c:\\Python38\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py\", line 297, in fit\n",
      "    return self._fit(X, y, self.max_samples, sample_weight=sample_weight)\n",
      "  File \"c:\\Python38\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py\", line 368, in _fit\n",
      "    raise ValueError(\"max_samples must be in (0, n_samples]\")\n",
      "ValueError: max_samples must be in (0, n_samples]\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "histgb: nan (+/-nan)\n",
      "ada: nan (+/-nan)\n",
      "bag: nan (+/-nan)\n",
      "et: nan (+/-nan)\n",
      "rf: nan (+/-nan)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Python38\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 106, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"c:\\Python38\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 384, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
      "  File \"c:\\Python38\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 571, in roc_auc_score\n",
      "    return _average_binary_score(\n",
      "  File \"c:\\Python38\\lib\\site-packages\\sklearn\\metrics\\_base.py\", line 75, in _average_binary_score\n",
      "    return binary_metric(y_true, y_score, sample_weight=sample_weight)\n",
      "  File \"c:\\Python38\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 339, in _binary_roc_auc_score\n",
      "    raise ValueError(\n",
      "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Python38\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 106, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"c:\\Python38\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 384, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
      "  File \"c:\\Python38\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 571, in roc_auc_score\n",
      "    return _average_binary_score(\n",
      "  File \"c:\\Python38\\lib\\site-packages\\sklearn\\metrics\\_base.py\", line 75, in _average_binary_score\n",
      "    return binary_metric(y_true, y_score, sample_weight=sample_weight)\n",
      "  File \"c:\\Python38\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 339, in _binary_roc_auc_score\n",
      "    raise ValueError(\n",
      "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Python38\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 106, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"c:\\Python38\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 384, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
      "  File \"c:\\Python38\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 571, in roc_auc_score\n",
      "    return _average_binary_score(\n",
      "  File \"c:\\Python38\\lib\\site-packages\\sklearn\\metrics\\_base.py\", line 75, in _average_binary_score\n",
      "    return binary_metric(y_true, y_score, sample_weight=sample_weight)\n",
      "  File \"c:\\Python38\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 339, in _binary_roc_auc_score\n",
      "    raise ValueError(\n",
      "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Python38\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 106, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"c:\\Python38\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 384, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
      "  File \"c:\\Python38\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 571, in roc_auc_score\n",
      "    return _average_binary_score(\n",
      "  File \"c:\\Python38\\lib\\site-packages\\sklearn\\metrics\\_base.py\", line 75, in _average_binary_score\n",
      "    return binary_metric(y_true, y_score, sample_weight=sample_weight)\n",
      "  File \"c:\\Python38\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 339, in _binary_roc_auc_score\n",
      "    raise ValueError(\n",
      "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "for name, clf in model_dict.items():\n",
    "    scores = cross_val_score(estimator=clf, X=X, y=y, cv=2, scoring='roc_auc')\n",
    "    print('%s: %.5f (+/-%.5f)' % (name, scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting = VotingRegressor([('gdboost', gb), ('lgbm', lgbm), ('catboost', catb)], weights=[0.99, 0.99, 0.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
